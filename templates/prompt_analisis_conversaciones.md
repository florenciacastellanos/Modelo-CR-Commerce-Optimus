# ü§ñ Template de Prompt - An√°lisis de Conversaciones con LLM

## Prop√≥sito

Este prompt est√° dise√±ado para analizar conversaciones de atenci√≥n al cliente y extraer:
- **Causas ra√≠z espec√≠ficas** (no gen√©ricas)
- **Frecuencias exactas** con cobertura ‚â•80%
- **Citas textuales reales** con CASE_IDs
- **Sentimiento** (frustraci√≥n/satisfacci√≥n)

---

## üìä Par√°metros a reemplazar

- `{PROCESS_NAME}` ‚Üí Nombre del proceso analizado (ej: "Defectuoso - Flex")
- `{N}` ‚Üí Cantidad de conversaciones en la muestra (ej: 100)
- `{CSV_DATA_PROCESO}` ‚Üí Datos del CSV en formato estructurado (ver formato abajo)
- `{COMMERCE_GROUP}` ‚Üí Grupo de commerce (ej: "PDD")

---

## üéØ Prompt Template

```markdown
Eres un analista experto en Customer Experience de MercadoLibre.

**‚ö†Ô∏è VALIDACI√ìN PREVIA:**
- Se requiere un M√çNIMO de 10 conversaciones para realizar an√°lisis v√°lido
- Si N < 10: Retornar JSON con estado "MUESTRA_INSUFICIENTE" y sin causas

Analiza estas {N} conversaciones del proceso "{PROCESS_NAME}" del commerce group "{COMMERCE_GROUP}":

**CONVERSACIONES ({N} casos):**

{CSV_DATA_PROCESO}

---

**TAREA (sin cantidad fija):**
1. Identifica **causas ra√≠z** lo m√°s ESPEC√çFICAS posible (no gen√©ricas).
2. Ord√©nalas por frecuencia hasta que la suma alcance **‚â•80%** de las menciones.
3. Para cada causa, estima:
   - Frecuencia absoluta (X/{N} conversaciones)
   - Porcentaje (%)
   - CASE_IDs de ejemplo (usar IDs reales del texto arriba)
4. Extrae 2-3 citas textuales representativas por causa.
5. Estima sentimiento por causa (frustraci√≥n % / satisfacci√≥n post-resoluci√≥n %).

**CRITERIOS CR√çTICOS:**
- Ser MUY ESPEC√çFICO:
  - ‚ùå "Problemas de entrega" 
  - ‚úÖ "Productos da√±ados por mal embalaje en despachos post-Navidad"
  - ‚ùå "Consultas sobre producto" 
  - ‚úÖ "Validaci√≥n de fotos rechazada por formato incorrecto"
- Solo incluir causas con ‚â•3 menciones en la muestra
- Los CASE_IDs deben ser reales (de los mostrados arriba)
- Las citas deben ser fragmentos exactos de las conversaciones (no parafrasear)
- Los porcentajes deben sumar ‚â•80% (idealmente ~100% incluyendo remanente "Otros")

**FORMATO DE RESPUESTA (JSON estricto):**

‚ö†Ô∏è **CR√çTICO - REGLAS DE LONGITUD:**
1. `"causa"`: M√°ximo 6-10 palabras (t√≠tulo ejecutivo)
2. `"descripcion"`: 1-2 oraciones, 20-30 palabras (contexto espec√≠fico)
3. **NO duplicar texto entre "causa" y "descripcion"**
4. `"sentimiento"`: Formato string "X% frustraci√≥n, Y% satisfacci√≥n"
5. `"cobertura"`: N√∫mero simple (no objeto)

{
  "proceso": "{PROCESS_NAME}",
  "total_conversaciones": {N},
  "causas": [
    {
      "causa": "T√≠tulo corto de la causa ra√≠z (6-10 palabras)",
      "porcentaje": 42,
      "casos_estimados": 42,  // ‚Üê round((porcentaje / 100) √ó total_conversaciones). Frecuencia REAL de la muestra, NO extrapolar a incoming total.
      "descripcion": "Contexto espec√≠fico en 1-2 oraciones (20-30 palabras). No repetir la causa.",
      "citas": [
        {
          "case_id": "CASE_ID_1", 
          "texto": "Fragmento textual exacto de la conversaci√≥n"
        },
        {
          "case_id": "CASE_ID_2", 
          "texto": "Otro fragmento textual exacto"
        }
      ],
      "sentimiento": "72% frustraci√≥n, 28% satisfacci√≥n"
    }
  ],
  "cobertura": 100,
  "hallazgo_principal": "Resumen ejecutivo de 1-2 frases con el patr√≥n dominante"
}

**EJEMPLOS DE FORMATO CORRECTO:**

‚úÖ **BUENO:**
```json
{
  "causa": "Reembolso procesado pero no reflejado en cuenta",
  "descripcion": "Usuarios reportan que ML proces√≥ el reembolso pero el dinero no aparece en su cuenta bancaria. ML indica que el banco debe acreditar."
}
```

‚úÖ **BUENO:**
```json
{
  "causa": "Colectas no realizadas por falta de espacio",
  "descripcion": "Vendedores con alto volumen reportan colectas parciales o canceladas por falta de espacio en cami√≥n. Solicitan exclusi√≥n masiva."
}
```

‚úÖ **BUENO:**
```json
{
  "causa": "Demoras por cambios de horario sin aviso",
  "descripcion": "Vendedores reportan modificaciones de horarios de colecta sin notificaci√≥n previa, generando demoras masivas en m√∫ltiples ventas simult√°neas."
}
```

‚ùå **MALO (causa demasiado larga):**
```json
{
  "causa": "Vendedores con alto volumen reportan que las colectas no se realizaron o fueron parciales por falta de espacio"
}
```

‚ùå **MALO (texto duplicado):**
```json
{
  "causa": "Reembolso procesado pero no reflejado",
  "descripcion": "Reembolso procesado pero no reflejado en cuenta bancaria"
}
```

‚ùå **MALO (descripci√≥n demasiado gen√©rica):**
```json
{
  "causa": "Problemas con reputaci√≥n",
  "descripcion": "Usuarios tienen problemas con su reputaci√≥n"
}
```

**IMPORTANTE:**
- Los porcentajes son sobre la muestra analizada ({N} casos)
- La suma de porcentajes debe ser ‚â•80%
- `"causa"` debe ser concisa (6-10 palabras)
- `"descripcion"` debe agregar contexto espec√≠fico (no repetir causa)
- S√© espec√≠fico, no gen√©rico
- No inventes CASE_IDs ni citas

Responde SOLO con el JSON, sin texto adicional.
```

---

## üìù Formato de `{CSV_DATA_PROCESO}`

Formatear las conversaciones del CSV as√≠:

```
1. CASE_ID: 426491524 | Fecha: 2025-12-30
   "El comprador reporta que el producto pierde agua en la uni√≥n de la base con los laterales del recipiente. Solicita la devoluci√≥n del producto y menciona que lo necesita por recomendaci√≥n de su odont√≥logo..."

2. CASE_ID: 426253719 | Fecha: 2025-12-29
   "La compradora report√≥ que el aro inflable se desinfla r√°pidamente y no funciona, solicitando un cambio o la devoluci√≥n del dinero..."

[... continuar hasta las {N} conversaciones ...]
```

**Notas:**
- Limitar cada conversaci√≥n a ~200 caracteres para no exceder l√≠mite de tokens
- Si hay >50 conversaciones, usar sample representativo de 50 y aclarar en el prompt

---

## ‚öôÔ∏è Par√°metros del LLM

**Modelo recomendado:** `gpt-4o-mini` o `claude-sonnet-3.5`
- **Ventaja:** R√°pido (~30s), econ√≥mico, preciso para tareas estructuradas

**Configuraci√≥n:**
```python
{
  "model": "gpt-4o-mini",
  "temperature": 0.3,         # Balance precisi√≥n/creatividad
  "max_tokens": 4096,         # Suficiente para JSON estructurado
  "response_format": "json"   # Forzar output JSON (si disponible)
}
```

**System prompt:**
```
"Eres un analista de datos experto. Respondes solo en formato JSON v√°lido."
```

**Max retries:** 2 (con backoff exponencial)

---

## ‚úÖ Validaci√≥n del Output

Despu√©s de recibir el JSON del LLM, validar:

```python
# 1. Parsear JSON
try:
    result = json.loads(llm_response)
except:
    # Fallback: an√°lisis manual

# 2. Verificar estructura
assert 'causas' in result
assert 'cobertura' in result
assert len(result['causas']) > 0

# 3. Verificar CASE_IDs reales
for causa in result['causas']:
    for case_id in causa['case_ids_ejemplo']:
        if case_id not in df['CAS_CASE_ID'].astype(str).values:
            # Reemplazar con CASE_ID real del CSV
            causa['case_ids_ejemplo'] = [df.sample(1)['CAS_CASE_ID'].iloc[0]]

# 4. Verificar cobertura ‚â•80%
if result['cobertura']['covered'] < 80:
    # Agregar causa "Otros / Volum√©trico"
    result['causas'].append({
        "descripcion": "Otros / Volum√©trico",
        "frecuencia_porcentaje": result['cobertura']['remainder']
    })

# 5. Verificar suma de porcentajes
total_pct = sum([c['frecuencia_porcentaje'] for c in result['causas']])
if abs(total_pct - 100) > 10:
    # Recalcular proporcionalmente
    for causa in result['causas']:
        causa['frecuencia_porcentaje'] = (causa['frecuencia_porcentaje'] / total_pct) * 100
```

---

## üöÄ Ejemplo de Uso Completo

```python
# 1. Leer CSV de muestreo unificado
df = pd.read_csv('output/muestreo_unificado.csv')

# 2. Filtrar por proceso
proceso = "Defectuoso - Flex"
df_proceso = df[df['PROCESS_NAME'] == proceso]

# 3. Formatear conversaciones
csv_data = ""
for i, row in df_proceso.iterrows():
    csv_data += f"{i+1}. CASE_ID: {row['CAS_CASE_ID']} | Fecha: {row['FECHA_CONTACTO']}\n"
    csv_data += f'   "{row['CONVERSATION_SUMMARY'][:200]}..."\n\n'

# 4. Reemplazar placeholders en prompt
prompt = PROMPT_TEMPLATE.replace('{PROCESS_NAME}', proceso)
prompt = prompt.replace('{N}', str(len(df_proceso)))
prompt = prompt.replace('{CSV_DATA_PROCESO}', csv_data)
prompt = prompt.replace('{COMMERCE_GROUP}', 'PDD')

# 5. Llamar a LLM
response = llm_client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "Eres un analista de datos experto. Respondes solo en JSON v√°lido."},
        {"role": "user", "content": prompt}
    ],
    temperature=0.3
)

# 6. Parsear y validar
result = json.loads(response.choices[0].message.content)
# ... validaciones ...

# 7. Usar en reporte HTML
for causa in result['causas']:
    html += f"<li><strong>{causa['descripcion']}</strong> ({causa['frecuencia_porcentaje']}%)</li>"
```

---

## üìö Referencias

- **Inspirado en:** `docs/V37.ipynb` - funci√≥n `analyze_conversations_with_gpt_v11()`
- **Reglas de Oro:** `.cursorrules` - Regla #9 (v5.0)
- **Query relacionada:** `sql/templates/muestreo_unificado_template.sql`

---

## üéØ M√©tricas de √âxito

| M√©trica | Target | Actual (ejemplo) |
|---------|--------|------------------|
| **Conversaciones m√≠nimas** | **‚â•10** | **Validaci√≥n autom√°tica** |
| Tiempo de an√°lisis | <45s | ~30s |
| Cobertura | ‚â•80% | 82% |
| CASE_IDs v√°lidos | 100% | 100% |
| Citas textuales | ‚â•2 por causa | 2-3 |
| Especificidad | Alta | ‚úÖ "Productos da√±ados post-Navidad" |

**‚ö†Ô∏è Nota sobre Umbral M√≠nimo:**
- Con **< 10 conversaciones**: Se reporta autom√°ticamente como "Muestra insuficiente"
- Con **‚â• 10 conversaciones**: An√°lisis v√°lido y concluyente
- El sistema valida esto ANTES de llamar al LLM para evitar an√°lisis inv√°lidos
